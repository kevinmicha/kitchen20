{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1e97ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Db = 'U8k'\n",
    "Db = 'K20'\n",
    "\n",
    "if Db == 'U8k':\n",
    "    local_config = {\n",
    "        'data_path'     : 'UrbanSound8K/audio',\n",
    "        'metadata_file' : 'UrbanSound8K/metadata/UrbanSound8K.csv',\n",
    "        'nb_classes'    :  10,}\n",
    "else:\n",
    "    local_config = {\n",
    "        'data_path'     : '/',\n",
    "        'metadata_file' : 'kitchen20b.csv',\n",
    "        'nb_classes'    :  20,}  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e21bfa3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'kitchen20b.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4j/fmrt0mln14zcmrb74g6z93bh0000gn/T/ipykernel_1060/1781591010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmetadata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LAB_3.9/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LAB_3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LAB_3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LAB_3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LAB_3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LAB_3.9/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LAB_3.9/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/LAB_3.9/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'kitchen20b.csv'"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Prepare training data from Metadata file\n",
    "# ----------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = local_config['data_path']\n",
    "\n",
    "# Read metadata file\n",
    "metadata_file = local_config['metadata_file']\n",
    "\n",
    "df = pd.read_csv(metadata_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f4ce9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>classID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio/0-158737-A-0.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio/0-158737-B-0.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio/0-158737-C-0.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio/0-173319-A-0.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio/0-173319-B-0.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            relative_path  classID\n",
       "0  audio/0-158737-A-0.wav        0\n",
       "1  audio/0-158737-B-0.wav        0\n",
       "2  audio/0-158737-C-0.wav        0\n",
       "3  audio/0-173319-A-0.wav        0\n",
       "4  audio/0-173319-B-0.wav        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct file path by concatenating fold and file name\n",
    "if Db == 'U8k':\n",
    "    df['path'] = '/fold' + df['fold'].astype(str) + '/' + df['slice_file_name'].astype(str) # Urban8k\n",
    "\n",
    "# Take relevant columns\n",
    "df = df[['path', 'target']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5391408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "\n",
    "class AudioUtil():\n",
    "    # ----------------------------\n",
    "    # Load an audio file. Return the signal as a tensor and the sample rate\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def open(audio_file):\n",
    "        sig, sr = torchaudio.load(audio_file)\n",
    "        return (sig, sr)\n",
    "    # ----------------------------\n",
    "    # Convert the given audio to the desired number of channels\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def rechannel(aud, new_channel):\n",
    "        sig, sr = aud\n",
    "\n",
    "        if (sig.shape[0] == new_channel):\n",
    "          # Nothing to do\n",
    "          return aud\n",
    "\n",
    "        if (new_channel == 1):\n",
    "          # Convert from stereo to mono by selecting only the first channel\n",
    "          resig = sig[:1, :]\n",
    "        else:\n",
    "          # Convert from mono to stereo by duplicating the first channel\n",
    "          resig = torch.cat([sig, sig])\n",
    "\n",
    "        return ((resig, sr))\n",
    "    # ----------------------------\n",
    "    # Since Resample applies to a single channel, we resample one channel at a time\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def resample(aud, newsr):\n",
    "        sig, sr = aud\n",
    "\n",
    "        if (sr == newsr):\n",
    "            # Nothing to do\n",
    "            return aud\n",
    "\n",
    "        num_channels = sig.shape[0]\n",
    "        # Resample first channel\n",
    "        resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "        if (num_channels > 1):\n",
    "            # Resample the second channel and merge both channels\n",
    "            retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "            resig = torch.cat([resig, retwo])\n",
    "\n",
    "        return ((resig, newsr))\n",
    "    # ----------------------------\n",
    "    # Pad (or truncate) the signal to a fixed length 'max_ms' in milliseconds\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def pad_trunc(aud, max_ms):\n",
    "        sig, sr = aud\n",
    "        num_rows, sig_len = sig.shape\n",
    "        max_len = sr//1000 * max_ms\n",
    "\n",
    "        if (sig_len > max_len):\n",
    "            # Truncate the signal to the given length\n",
    "            sig = sig[:,:max_len]\n",
    "\n",
    "        elif (sig_len < max_len):\n",
    "            # Length of padding to add at the beginning and end of the signal\n",
    "            pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "            pad_end_len = max_len - sig_len - pad_begin_len\n",
    "\n",
    "            # Pad with 0s\n",
    "            pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "            pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "\n",
    "            sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "\n",
    "        return (sig, sr)\n",
    "    # ----------------------------\n",
    "    # Shifts the signal to the left or right by some percent. Values at the end\n",
    "    # are 'wrapped around' to the start of the transformed signal.\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def time_shift(aud, shift_limit):\n",
    "        sig,sr = aud\n",
    "        _, sig_len = sig.shape\n",
    "        shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "        return (sig.roll(shift_amt), sr)\n",
    "    # ----------------------------\n",
    "    # Generate a Spectrogram\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        sig,sr = aud\n",
    "        top_db = 80\n",
    "\n",
    "        # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "        spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "        # Convert to decibels\n",
    "        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        return (spec)\n",
    "    # ----------------------------\n",
    "    # Augment the Spectrogram by masking out some sections of it in both the frequency\n",
    "    # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\n",
    "    # overfitting and to help the model generalise better. The masked sections are\n",
    "    # replaced with the mean value.\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "        _, n_mels, n_steps = spec.shape\n",
    "        mask_value = spec.mean()\n",
    "        aug_spec = spec\n",
    "\n",
    "        freq_mask_param = max_mask_pct * n_mels\n",
    "        for _ in range(n_freq_masks):\n",
    "            aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        time_mask_param = max_mask_pct * n_steps\n",
    "        for _ in range(n_time_masks):\n",
    "            aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        return aug_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ff73be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio\n",
    "\n",
    "# ----------------------------\n",
    "# Sound Dataset\n",
    "# ----------------------------\n",
    "class SoundDS(Dataset):\n",
    "    def __init__(self, df, data_path):\n",
    "        self.df = df\n",
    "        self.data_path = str(data_path)\n",
    "        self.duration = 4000\n",
    "        self.sr = 44100\n",
    "        self.channel = 2\n",
    "        self.shift_pct = 0.4\n",
    "\n",
    "    # ----------------------------\n",
    "    # Number of items in dataset\n",
    "    # ----------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "\n",
    "    # ----------------------------\n",
    "    # Get i'th item in dataset\n",
    "    # ----------------------------\n",
    "    def __getitem__(self, idx):\n",
    "        # Absolute file path of the audio file - concatenate the audio directory with\n",
    "        # the relative path\n",
    "        audio_file = self.data_path + self.df.loc[idx, 'path']\n",
    "        # Get the Class ID\n",
    "        class_id = self.df.loc[idx, 'target']\n",
    "\n",
    "        aud = AudioUtil.open(audio_file)\n",
    "        # Some sounds have a higher sample rate, or fewer channels compared to the\n",
    "        # majority. So make all sounds have the same number of channels and same \n",
    "        # sample rate. Unless the sample rate is the same, the pad_trunc will still\n",
    "        # result in arrays of different lengths, even though the sound duration is\n",
    "        # the same.\n",
    "        reaud = AudioUtil.resample(aud, self.sr)\n",
    "        rechan = AudioUtil.rechannel(reaud, self.channel)\n",
    "\n",
    "        dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n",
    "        shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n",
    "        sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "        aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "        return aug_sgram, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bacd510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "myds = SoundDS(df, data_path)\n",
    "\n",
    "# Random split of 80:20 between training and validation\n",
    "num_items = len(myds)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
    "\n",
    "# Create training and validation data loaders\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ede532e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "\n",
    "# ----------------------------\n",
    "# Audio Classification Model\n",
    "# ----------------------------\n",
    "class AudioClassifier (nn.Module):\n",
    "    # ----------------------------\n",
    "    # Build the model architecture\n",
    "    # ----------------------------\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_layers = []\n",
    "\n",
    "        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\n",
    "        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
    "        self.conv2.bias.data.zero_()\n",
    "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
    "        self.conv3.bias.data.zero_()\n",
    "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
    "\n",
    "#         # Second Convolution Block\n",
    "#         self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "#         self.relu4 = nn.ReLU()\n",
    "#         self.bn4 = nn.BatchNorm2d(64)\n",
    "#         init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
    "#         self.conv4.bias.data.zero_()\n",
    "#         conv_layers += [self.conv4, self.relu4, self.bn4]\n",
    "\n",
    "#         # Linear Classifier\n",
    "#         self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "#         self.lin = nn.Linear(in_features=64, out_features=local_config['nb_classes'])\n",
    "\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin = nn.Linear(in_features=32, out_features=local_config['nb_classes'])\n",
    "\n",
    "        # Wrap the Convolutional Blocks\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    " \n",
    "    # ----------------------------\n",
    "    # Forward pass computations\n",
    "    # ----------------------------\n",
    "    def forward(self, x):\n",
    "        # Run the convolutional blocks\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # Adaptive pool and flatten for input to linear layer\n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Linear layer\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Final output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b5c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torchsummary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeb7a0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 8, 2000, 32]             408\n",
      "            Conv2d-2          [-1, 8, 2000, 32]             408\n",
      "              ReLU-3          [-1, 8, 2000, 32]               0\n",
      "              ReLU-4          [-1, 8, 2000, 32]               0\n",
      "       BatchNorm2d-5          [-1, 8, 2000, 32]              16\n",
      "       BatchNorm2d-6          [-1, 8, 2000, 32]              16\n",
      "            Conv2d-7         [-1, 16, 1000, 16]           1,168\n",
      "            Conv2d-8         [-1, 16, 1000, 16]           1,168\n",
      "              ReLU-9         [-1, 16, 1000, 16]               0\n",
      "             ReLU-10         [-1, 16, 1000, 16]               0\n",
      "      BatchNorm2d-11         [-1, 16, 1000, 16]              32\n",
      "      BatchNorm2d-12         [-1, 16, 1000, 16]              32\n",
      "           Conv2d-13           [-1, 32, 500, 8]           4,640\n",
      "           Conv2d-14           [-1, 32, 500, 8]           4,640\n",
      "             ReLU-15           [-1, 32, 500, 8]               0\n",
      "             ReLU-16           [-1, 32, 500, 8]               0\n",
      "      BatchNorm2d-17           [-1, 32, 500, 8]              64\n",
      "      BatchNorm2d-18           [-1, 32, 500, 8]              64\n",
      "AdaptiveAvgPool2d-19             [-1, 32, 1, 1]               0\n",
      "           Linear-20                   [-1, 20]             660\n",
      "================================================================\n",
      "Total params: 13,316\n",
      "Trainable params: 13,316\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.95\n",
      "Forward/backward pass size (MB): 41.02\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 43.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "myModel = AudioClassifier()\n",
    "summary(myModel,(2, 4000, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef57b24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'local_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2947/810012909.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create the model and put it on the GPU if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmyModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmyModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2947/3768319800.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaptiveAvgPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb_classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Wrap the Convolutional Blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'local_config' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the model and put it on the GPU if available\n",
    "myModel = AudioClassifier()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "myModel = myModel.to(device)\n",
    "\n",
    "# Check that it is on Cuda\n",
    "next(myModel.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9570f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Training Loop\n",
    "# ----------------------------\n",
    "def training(model, train_dl, num_epochs):\n",
    "    # Loss Function, Optimizer and Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.05,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs,\n",
    "                                                anneal_strategy='linear')\n",
    "\n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "\n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "            #if i % 10 == 0:    # print every 10 mini-batches\n",
    "            #    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "\n",
    "        # Print stats at the end of the epoch\n",
    "        num_batches = len(train_dl)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        acc = correct_prediction/total_prediction\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
    "\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae2025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.80, Accuracy: 0.11\n",
      "Epoch: 1, Loss: 2.55, Accuracy: 0.17\n",
      "Epoch: 2, Loss: 2.36, Accuracy: 0.24\n",
      "Epoch: 3, Loss: 2.18, Accuracy: 0.28\n",
      "Epoch: 4, Loss: 2.09, Accuracy: 0.33\n",
      "Epoch: 5, Loss: 1.96, Accuracy: 0.34\n",
      "Epoch: 6, Loss: 1.88, Accuracy: 0.39\n",
      "Epoch: 7, Loss: 1.82, Accuracy: 0.36\n",
      "Epoch: 8, Loss: 1.79, Accuracy: 0.40\n",
      "Epoch: 9, Loss: 1.74, Accuracy: 0.41\n",
      "Epoch: 10, Loss: 1.70, Accuracy: 0.41\n",
      "Epoch: 11, Loss: 1.64, Accuracy: 0.44\n",
      "Epoch: 12, Loss: 1.63, Accuracy: 0.45\n",
      "Epoch: 13, Loss: 1.61, Accuracy: 0.45\n",
      "Epoch: 14, Loss: 1.47, Accuracy: 0.51\n",
      "Epoch: 15, Loss: 1.53, Accuracy: 0.47\n",
      "Epoch: 16, Loss: 1.44, Accuracy: 0.51\n",
      "Epoch: 17, Loss: 1.40, Accuracy: 0.52\n",
      "Epoch: 18, Loss: 1.45, Accuracy: 0.53\n",
      "Epoch: 19, Loss: 1.37, Accuracy: 0.56\n",
      "Epoch: 20, Loss: 1.36, Accuracy: 0.52\n",
      "Epoch: 21, Loss: 1.29, Accuracy: 0.57\n",
      "Epoch: 22, Loss: 1.28, Accuracy: 0.57\n",
      "Epoch: 23, Loss: 1.35, Accuracy: 0.55\n",
      "Epoch: 24, Loss: 1.21, Accuracy: 0.60\n",
      "Epoch: 25, Loss: 1.26, Accuracy: 0.58\n",
      "Epoch: 26, Loss: 1.26, Accuracy: 0.57\n",
      "Epoch: 27, Loss: 1.14, Accuracy: 0.61\n",
      "Epoch: 28, Loss: 1.23, Accuracy: 0.58\n",
      "Epoch: 29, Loss: 1.19, Accuracy: 0.60\n",
      "Epoch: 30, Loss: 1.08, Accuracy: 0.64\n",
      "Epoch: 31, Loss: 1.11, Accuracy: 0.60\n",
      "Epoch: 32, Loss: 1.03, Accuracy: 0.67\n",
      "Epoch: 33, Loss: 1.06, Accuracy: 0.65\n",
      "Epoch: 34, Loss: 1.03, Accuracy: 0.63\n",
      "Epoch: 35, Loss: 1.09, Accuracy: 0.63\n",
      "Epoch: 36, Loss: 1.15, Accuracy: 0.62\n",
      "Epoch: 37, Loss: 1.03, Accuracy: 0.64\n",
      "Epoch: 38, Loss: 0.95, Accuracy: 0.67\n",
      "Epoch: 39, Loss: 0.98, Accuracy: 0.64\n",
      "Epoch: 40, Loss: 0.96, Accuracy: 0.67\n",
      "Epoch: 41, Loss: 0.95, Accuracy: 0.70\n",
      "Epoch: 42, Loss: 1.08, Accuracy: 0.64\n",
      "Epoch: 43, Loss: 0.94, Accuracy: 0.69\n",
      "Epoch: 44, Loss: 1.00, Accuracy: 0.67\n",
      "Epoch: 45, Loss: 1.05, Accuracy: 0.64\n",
      "Epoch: 46, Loss: 0.90, Accuracy: 0.69\n",
      "Epoch: 47, Loss: 0.99, Accuracy: 0.67\n",
      "Epoch: 48, Loss: 1.01, Accuracy: 0.67\n",
      "Epoch: 49, Loss: 1.01, Accuracy: 0.66\n",
      "Epoch: 50, Loss: 0.86, Accuracy: 0.69\n",
      "Epoch: 51, Loss: 0.92, Accuracy: 0.69\n",
      "Epoch: 52, Loss: 0.90, Accuracy: 0.69\n",
      "Epoch: 53, Loss: 0.97, Accuracy: 0.66\n",
      "Epoch: 54, Loss: 0.95, Accuracy: 0.67\n",
      "Epoch: 55, Loss: 0.93, Accuracy: 0.68\n",
      "Epoch: 56, Loss: 0.88, Accuracy: 0.69\n",
      "Epoch: 57, Loss: 0.89, Accuracy: 0.69\n",
      "Epoch: 58, Loss: 0.98, Accuracy: 0.68\n",
      "Epoch: 59, Loss: 0.89, Accuracy: 0.70\n",
      "Epoch: 60, Loss: 0.91, Accuracy: 0.71\n",
      "Epoch: 61, Loss: 0.92, Accuracy: 0.69\n",
      "Epoch: 62, Loss: 0.93, Accuracy: 0.67\n",
      "Epoch: 63, Loss: 1.00, Accuracy: 0.66\n",
      "Epoch: 64, Loss: 0.87, Accuracy: 0.70\n",
      "Epoch: 65, Loss: 0.85, Accuracy: 0.71\n",
      "Epoch: 66, Loss: 0.92, Accuracy: 0.70\n",
      "Epoch: 67, Loss: 1.00, Accuracy: 0.66\n",
      "Epoch: 68, Loss: 0.91, Accuracy: 0.70\n",
      "Epoch: 69, Loss: 0.87, Accuracy: 0.70\n",
      "Epoch: 70, Loss: 0.86, Accuracy: 0.70\n",
      "Epoch: 71, Loss: 0.90, Accuracy: 0.70\n",
      "Epoch: 72, Loss: 0.89, Accuracy: 0.69\n",
      "Epoch: 73, Loss: 0.96, Accuracy: 0.69\n",
      "Epoch: 74, Loss: 0.85, Accuracy: 0.71\n",
      "Epoch: 75, Loss: 0.80, Accuracy: 0.73\n",
      "Epoch: 76, Loss: 0.86, Accuracy: 0.69\n",
      "Epoch: 77, Loss: 0.82, Accuracy: 0.72\n",
      "Epoch: 78, Loss: 0.89, Accuracy: 0.68\n",
      "Epoch: 79, Loss: 0.89, Accuracy: 0.71\n",
      "Epoch: 80, Loss: 0.78, Accuracy: 0.75\n",
      "Epoch: 81, Loss: 0.85, Accuracy: 0.72\n",
      "Epoch: 82, Loss: 0.97, Accuracy: 0.68\n",
      "Epoch: 83, Loss: 0.93, Accuracy: 0.68\n",
      "Epoch: 84, Loss: 0.93, Accuracy: 0.69\n",
      "Epoch: 85, Loss: 0.84, Accuracy: 0.72\n",
      "Epoch: 86, Loss: 0.74, Accuracy: 0.73\n",
      "Epoch: 87, Loss: 0.88, Accuracy: 0.71\n",
      "Epoch: 88, Loss: 0.92, Accuracy: 0.69\n",
      "Epoch: 89, Loss: 0.76, Accuracy: 0.74\n",
      "Epoch: 90, Loss: 0.74, Accuracy: 0.75\n",
      "Epoch: 91, Loss: 0.81, Accuracy: 0.73\n",
      "Epoch: 92, Loss: 0.93, Accuracy: 0.70\n",
      "Epoch: 93, Loss: 0.84, Accuracy: 0.71\n",
      "Epoch: 94, Loss: 0.81, Accuracy: 0.75\n",
      "Epoch: 95, Loss: 0.78, Accuracy: 0.73\n",
      "Epoch: 96, Loss: 0.90, Accuracy: 0.71\n",
      "Epoch: 97, Loss: 0.86, Accuracy: 0.72\n",
      "Epoch: 98, Loss: 0.98, Accuracy: 0.69\n",
      "Epoch: 99, Loss: 0.89, Accuracy: 0.69\n",
      "Epoch: 100, Loss: 0.85, Accuracy: 0.72\n",
      "Epoch: 101, Loss: 0.89, Accuracy: 0.72\n",
      "Epoch: 102, Loss: 0.81, Accuracy: 0.72\n",
      "Epoch: 103, Loss: 0.85, Accuracy: 0.72\n",
      "Epoch: 104, Loss: 0.77, Accuracy: 0.73\n",
      "Epoch: 105, Loss: 0.71, Accuracy: 0.77\n",
      "Epoch: 106, Loss: 0.84, Accuracy: 0.73\n",
      "Epoch: 107, Loss: 0.92, Accuracy: 0.69\n",
      "Epoch: 108, Loss: 0.76, Accuracy: 0.74\n",
      "Epoch: 109, Loss: 0.83, Accuracy: 0.71\n",
      "Epoch: 110, Loss: 0.85, Accuracy: 0.72\n",
      "Epoch: 111, Loss: 0.85, Accuracy: 0.72\n",
      "Epoch: 112, Loss: 0.89, Accuracy: 0.70\n",
      "Epoch: 113, Loss: 0.84, Accuracy: 0.72\n",
      "Epoch: 114, Loss: 0.81, Accuracy: 0.74\n",
      "Epoch: 115, Loss: 0.89, Accuracy: 0.70\n",
      "Epoch: 116, Loss: 0.88, Accuracy: 0.71\n",
      "Epoch: 117, Loss: 0.85, Accuracy: 0.72\n",
      "Epoch: 118, Loss: 0.83, Accuracy: 0.73\n",
      "Epoch: 119, Loss: 0.81, Accuracy: 0.76\n",
      "Epoch: 120, Loss: 0.82, Accuracy: 0.72\n",
      "Epoch: 121, Loss: 0.80, Accuracy: 0.72\n",
      "Epoch: 122, Loss: 0.86, Accuracy: 0.71\n",
      "Epoch: 123, Loss: 0.92, Accuracy: 0.71\n",
      "Epoch: 124, Loss: 0.79, Accuracy: 0.74\n",
      "Epoch: 125, Loss: 0.80, Accuracy: 0.72\n",
      "Epoch: 126, Loss: 0.81, Accuracy: 0.73\n",
      "Epoch: 127, Loss: 0.82, Accuracy: 0.72\n",
      "Epoch: 128, Loss: 0.82, Accuracy: 0.71\n",
      "Epoch: 129, Loss: 0.78, Accuracy: 0.74\n",
      "Epoch: 130, Loss: 0.78, Accuracy: 0.74\n",
      "Epoch: 131, Loss: 0.81, Accuracy: 0.74\n",
      "Epoch: 132, Loss: 0.72, Accuracy: 0.76\n",
      "Epoch: 133, Loss: 0.85, Accuracy: 0.71\n",
      "Epoch: 134, Loss: 0.87, Accuracy: 0.71\n",
      "Epoch: 135, Loss: 0.72, Accuracy: 0.77\n",
      "Epoch: 136, Loss: 0.81, Accuracy: 0.74\n",
      "Epoch: 137, Loss: 0.80, Accuracy: 0.72\n",
      "Epoch: 138, Loss: 0.92, Accuracy: 0.71\n",
      "Epoch: 139, Loss: 0.78, Accuracy: 0.74\n",
      "Epoch: 140, Loss: 0.76, Accuracy: 0.73\n",
      "Epoch: 141, Loss: 0.82, Accuracy: 0.73\n",
      "Epoch: 142, Loss: 0.80, Accuracy: 0.73\n",
      "Epoch: 143, Loss: 0.77, Accuracy: 0.74\n",
      "Epoch: 144, Loss: 0.77, Accuracy: 0.74\n",
      "Epoch: 145, Loss: 0.95, Accuracy: 0.68\n",
      "Epoch: 146, Loss: 0.87, Accuracy: 0.71\n",
      "Epoch: 147, Loss: 0.81, Accuracy: 0.74\n",
      "Epoch: 148, Loss: 0.69, Accuracy: 0.75\n",
      "Epoch: 149, Loss: 0.90, Accuracy: 0.71\n",
      "Epoch: 150, Loss: 0.80, Accuracy: 0.74\n",
      "Epoch: 151, Loss: 0.86, Accuracy: 0.73\n",
      "Epoch: 152, Loss: 0.74, Accuracy: 0.76\n",
      "Epoch: 153, Loss: 0.87, Accuracy: 0.71\n",
      "Epoch: 154, Loss: 0.87, Accuracy: 0.70\n",
      "Epoch: 155, Loss: 0.76, Accuracy: 0.76\n",
      "Epoch: 156, Loss: 0.75, Accuracy: 0.75\n",
      "Epoch: 157, Loss: 0.75, Accuracy: 0.73\n",
      "Epoch: 158, Loss: 0.83, Accuracy: 0.72\n",
      "Epoch: 159, Loss: 0.76, Accuracy: 0.74\n",
      "Epoch: 160, Loss: 0.79, Accuracy: 0.74\n",
      "Epoch: 161, Loss: 0.75, Accuracy: 0.75\n",
      "Epoch: 162, Loss: 0.82, Accuracy: 0.74\n",
      "Epoch: 163, Loss: 0.83, Accuracy: 0.73\n",
      "Epoch: 164, Loss: 0.75, Accuracy: 0.75\n",
      "Epoch: 165, Loss: 0.72, Accuracy: 0.76\n",
      "Epoch: 166, Loss: 0.74, Accuracy: 0.76\n",
      "Epoch: 167, Loss: 0.73, Accuracy: 0.77\n",
      "Epoch: 168, Loss: 0.82, Accuracy: 0.74\n",
      "Epoch: 169, Loss: 0.76, Accuracy: 0.76\n",
      "Epoch: 170, Loss: 0.76, Accuracy: 0.77\n",
      "Epoch: 171, Loss: 0.74, Accuracy: 0.75\n",
      "Epoch: 172, Loss: 0.74, Accuracy: 0.76\n",
      "Epoch: 173, Loss: 0.70, Accuracy: 0.76\n",
      "Epoch: 174, Loss: 0.71, Accuracy: 0.77\n",
      "Epoch: 175, Loss: 0.80, Accuracy: 0.73\n",
      "Epoch: 176, Loss: 0.70, Accuracy: 0.76\n",
      "Epoch: 177, Loss: 0.74, Accuracy: 0.75\n",
      "Epoch: 178, Loss: 0.68, Accuracy: 0.76\n",
      "Epoch: 179, Loss: 0.77, Accuracy: 0.75\n",
      "Epoch: 180, Loss: 0.67, Accuracy: 0.76\n",
      "Epoch: 181, Loss: 0.81, Accuracy: 0.73\n",
      "Epoch: 182, Loss: 0.79, Accuracy: 0.73\n",
      "Epoch: 183, Loss: 0.74, Accuracy: 0.76\n",
      "Epoch: 184, Loss: 0.61, Accuracy: 0.80\n",
      "Epoch: 185, Loss: 0.78, Accuracy: 0.76\n",
      "Epoch: 186, Loss: 0.78, Accuracy: 0.73\n",
      "Epoch: 187, Loss: 0.69, Accuracy: 0.78\n",
      "Epoch: 188, Loss: 0.77, Accuracy: 0.76\n",
      "Epoch: 189, Loss: 0.71, Accuracy: 0.76\n",
      "Epoch: 190, Loss: 0.68, Accuracy: 0.77\n",
      "Epoch: 191, Loss: 0.60, Accuracy: 0.79\n",
      "Epoch: 192, Loss: 0.71, Accuracy: 0.77\n",
      "Epoch: 193, Loss: 0.69, Accuracy: 0.77\n",
      "Epoch: 194, Loss: 0.63, Accuracy: 0.78\n",
      "Epoch: 195, Loss: 0.66, Accuracy: 0.80\n",
      "Epoch: 196, Loss: 0.59, Accuracy: 0.80\n",
      "Epoch: 197, Loss: 0.63, Accuracy: 0.80\n",
      "Epoch: 198, Loss: 0.62, Accuracy: 0.79\n",
      "Epoch: 199, Loss: 0.68, Accuracy: 0.77\n",
      "Epoch: 200, Loss: 0.72, Accuracy: 0.78\n",
      "Epoch: 201, Loss: 0.64, Accuracy: 0.77\n",
      "Epoch: 202, Loss: 0.69, Accuracy: 0.78\n",
      "Epoch: 203, Loss: 0.56, Accuracy: 0.81\n",
      "Epoch: 204, Loss: 0.65, Accuracy: 0.78\n",
      "Epoch: 205, Loss: 0.69, Accuracy: 0.77\n",
      "Epoch: 206, Loss: 0.60, Accuracy: 0.79\n",
      "Epoch: 207, Loss: 0.57, Accuracy: 0.81\n",
      "Epoch: 208, Loss: 0.58, Accuracy: 0.80\n",
      "Epoch: 209, Loss: 0.72, Accuracy: 0.78\n",
      "Epoch: 210, Loss: 0.54, Accuracy: 0.82\n",
      "Epoch: 211, Loss: 0.62, Accuracy: 0.81\n",
      "Epoch: 212, Loss: 0.58, Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 213, Loss: 0.59, Accuracy: 0.81\n",
      "Epoch: 214, Loss: 0.52, Accuracy: 0.83\n",
      "Epoch: 215, Loss: 0.57, Accuracy: 0.81\n",
      "Epoch: 216, Loss: 0.67, Accuracy: 0.80\n",
      "Epoch: 217, Loss: 0.70, Accuracy: 0.78\n",
      "Epoch: 218, Loss: 0.68, Accuracy: 0.77\n",
      "Epoch: 219, Loss: 0.60, Accuracy: 0.80\n",
      "Epoch: 220, Loss: 0.57, Accuracy: 0.82\n",
      "Epoch: 221, Loss: 0.58, Accuracy: 0.81\n",
      "Epoch: 222, Loss: 0.62, Accuracy: 0.81\n",
      "Epoch: 223, Loss: 0.57, Accuracy: 0.81\n",
      "Epoch: 224, Loss: 0.54, Accuracy: 0.82\n",
      "Epoch: 225, Loss: 0.47, Accuracy: 0.84\n",
      "Epoch: 226, Loss: 0.60, Accuracy: 0.81\n",
      "Epoch: 227, Loss: 0.50, Accuracy: 0.84\n",
      "Epoch: 228, Loss: 0.51, Accuracy: 0.81\n",
      "Epoch: 229, Loss: 0.57, Accuracy: 0.81\n",
      "Epoch: 230, Loss: 0.66, Accuracy: 0.79\n",
      "Epoch: 231, Loss: 0.58, Accuracy: 0.82\n",
      "Epoch: 232, Loss: 0.58, Accuracy: 0.81\n",
      "Epoch: 233, Loss: 0.55, Accuracy: 0.83\n",
      "Epoch: 234, Loss: 0.61, Accuracy: 0.79\n",
      "Epoch: 235, Loss: 0.58, Accuracy: 0.81\n",
      "Epoch: 236, Loss: 0.63, Accuracy: 0.81\n",
      "Epoch: 237, Loss: 0.58, Accuracy: 0.80\n",
      "Epoch: 238, Loss: 0.49, Accuracy: 0.83\n",
      "Epoch: 239, Loss: 0.56, Accuracy: 0.80\n",
      "Epoch: 240, Loss: 0.51, Accuracy: 0.83\n",
      "Epoch: 241, Loss: 0.57, Accuracy: 0.81\n",
      "Epoch: 242, Loss: 0.60, Accuracy: 0.81\n",
      "Epoch: 243, Loss: 0.50, Accuracy: 0.83\n",
      "Epoch: 244, Loss: 0.57, Accuracy: 0.80\n",
      "Epoch: 245, Loss: 0.59, Accuracy: 0.79\n",
      "Epoch: 246, Loss: 0.55, Accuracy: 0.82\n",
      "Epoch: 247, Loss: 0.56, Accuracy: 0.84\n",
      "Epoch: 248, Loss: 0.55, Accuracy: 0.83\n",
      "Epoch: 249, Loss: 0.54, Accuracy: 0.80\n",
      "Epoch: 250, Loss: 0.52, Accuracy: 0.81\n",
      "Epoch: 251, Loss: 0.61, Accuracy: 0.79\n",
      "Epoch: 252, Loss: 0.56, Accuracy: 0.81\n",
      "Epoch: 253, Loss: 0.59, Accuracy: 0.80\n",
      "Epoch: 254, Loss: 0.54, Accuracy: 0.82\n",
      "Epoch: 255, Loss: 0.51, Accuracy: 0.83\n",
      "Epoch: 256, Loss: 0.39, Accuracy: 0.88\n",
      "Epoch: 257, Loss: 0.62, Accuracy: 0.82\n",
      "Epoch: 258, Loss: 0.58, Accuracy: 0.81\n",
      "Epoch: 259, Loss: 0.58, Accuracy: 0.81\n",
      "Epoch: 260, Loss: 0.51, Accuracy: 0.85\n",
      "Epoch: 261, Loss: 0.50, Accuracy: 0.84\n",
      "Epoch: 262, Loss: 0.42, Accuracy: 0.87\n",
      "Epoch: 263, Loss: 0.47, Accuracy: 0.85\n",
      "Epoch: 264, Loss: 0.49, Accuracy: 0.84\n",
      "Epoch: 265, Loss: 0.48, Accuracy: 0.84\n",
      "Epoch: 266, Loss: 0.52, Accuracy: 0.82\n",
      "Epoch: 267, Loss: 0.44, Accuracy: 0.85\n",
      "Epoch: 268, Loss: 0.48, Accuracy: 0.83\n",
      "Epoch: 269, Loss: 0.57, Accuracy: 0.81\n",
      "Epoch: 270, Loss: 0.45, Accuracy: 0.84\n",
      "Epoch: 271, Loss: 0.47, Accuracy: 0.84\n",
      "Epoch: 272, Loss: 0.53, Accuracy: 0.83\n",
      "Epoch: 273, Loss: 0.45, Accuracy: 0.85\n",
      "Epoch: 274, Loss: 0.46, Accuracy: 0.84\n",
      "Epoch: 275, Loss: 0.54, Accuracy: 0.83\n",
      "Epoch: 276, Loss: 0.42, Accuracy: 0.86\n",
      "Epoch: 277, Loss: 0.47, Accuracy: 0.85\n",
      "Epoch: 278, Loss: 0.46, Accuracy: 0.85\n",
      "Epoch: 279, Loss: 0.49, Accuracy: 0.82\n",
      "Epoch: 280, Loss: 0.48, Accuracy: 0.83\n",
      "Epoch: 281, Loss: 0.44, Accuracy: 0.86\n",
      "Epoch: 282, Loss: 0.52, Accuracy: 0.83\n",
      "Epoch: 283, Loss: 0.49, Accuracy: 0.84\n",
      "Epoch: 284, Loss: 0.50, Accuracy: 0.83\n",
      "Epoch: 285, Loss: 0.45, Accuracy: 0.85\n",
      "Epoch: 286, Loss: 0.53, Accuracy: 0.83\n",
      "Epoch: 287, Loss: 0.40, Accuracy: 0.86\n",
      "Epoch: 288, Loss: 0.49, Accuracy: 0.84\n",
      "Epoch: 289, Loss: 0.45, Accuracy: 0.85\n",
      "Epoch: 290, Loss: 0.43, Accuracy: 0.86\n",
      "Epoch: 291, Loss: 0.54, Accuracy: 0.83\n",
      "Epoch: 292, Loss: 0.51, Accuracy: 0.84\n",
      "Epoch: 293, Loss: 0.50, Accuracy: 0.83\n",
      "Epoch: 294, Loss: 0.41, Accuracy: 0.87\n",
      "Epoch: 295, Loss: 0.48, Accuracy: 0.84\n",
      "Epoch: 296, Loss: 0.39, Accuracy: 0.86\n",
      "Epoch: 297, Loss: 0.44, Accuracy: 0.85\n",
      "Epoch: 298, Loss: 0.45, Accuracy: 0.84\n",
      "Epoch: 299, Loss: 0.48, Accuracy: 0.85\n",
      "Epoch: 300, Loss: 0.53, Accuracy: 0.84\n",
      "Epoch: 301, Loss: 0.56, Accuracy: 0.83\n",
      "Epoch: 302, Loss: 0.43, Accuracy: 0.85\n",
      "Epoch: 303, Loss: 0.45, Accuracy: 0.85\n",
      "Epoch: 304, Loss: 0.40, Accuracy: 0.85\n",
      "Epoch: 305, Loss: 0.48, Accuracy: 0.85\n",
      "Epoch: 306, Loss: 0.44, Accuracy: 0.85\n",
      "Epoch: 307, Loss: 0.48, Accuracy: 0.85\n",
      "Epoch: 308, Loss: 0.41, Accuracy: 0.86\n",
      "Epoch: 309, Loss: 0.37, Accuracy: 0.88\n",
      "Epoch: 310, Loss: 0.42, Accuracy: 0.86\n",
      "Epoch: 311, Loss: 0.36, Accuracy: 0.88\n",
      "Epoch: 312, Loss: 0.41, Accuracy: 0.86\n",
      "Epoch: 313, Loss: 0.46, Accuracy: 0.85\n",
      "Epoch: 314, Loss: 0.40, Accuracy: 0.86\n",
      "Epoch: 315, Loss: 0.41, Accuracy: 0.87\n",
      "Epoch: 316, Loss: 0.40, Accuracy: 0.87\n",
      "Epoch: 317, Loss: 0.42, Accuracy: 0.86\n",
      "Epoch: 318, Loss: 0.39, Accuracy: 0.88\n",
      "Epoch: 319, Loss: 0.33, Accuracy: 0.88\n",
      "Epoch: 320, Loss: 0.35, Accuracy: 0.87\n",
      "Epoch: 321, Loss: 0.43, Accuracy: 0.87\n",
      "Epoch: 322, Loss: 0.40, Accuracy: 0.87\n",
      "Epoch: 323, Loss: 0.49, Accuracy: 0.84\n",
      "Epoch: 324, Loss: 0.37, Accuracy: 0.87\n",
      "Epoch: 325, Loss: 0.44, Accuracy: 0.86\n",
      "Epoch: 326, Loss: 0.41, Accuracy: 0.86\n",
      "Epoch: 327, Loss: 0.43, Accuracy: 0.87\n",
      "Epoch: 328, Loss: 0.41, Accuracy: 0.87\n",
      "Epoch: 329, Loss: 0.47, Accuracy: 0.85\n",
      "Epoch: 330, Loss: 0.38, Accuracy: 0.88\n",
      "Epoch: 331, Loss: 0.44, Accuracy: 0.85\n",
      "Epoch: 332, Loss: 0.44, Accuracy: 0.86\n",
      "Epoch: 333, Loss: 0.35, Accuracy: 0.89\n",
      "Epoch: 334, Loss: 0.42, Accuracy: 0.86\n",
      "Epoch: 335, Loss: 0.39, Accuracy: 0.86\n",
      "Epoch: 336, Loss: 0.39, Accuracy: 0.87\n",
      "Epoch: 337, Loss: 0.34, Accuracy: 0.88\n",
      "Epoch: 338, Loss: 0.38, Accuracy: 0.87\n",
      "Epoch: 339, Loss: 0.40, Accuracy: 0.88\n",
      "Epoch: 340, Loss: 0.34, Accuracy: 0.89\n",
      "Epoch: 341, Loss: 0.42, Accuracy: 0.86\n",
      "Epoch: 342, Loss: 0.38, Accuracy: 0.89\n",
      "Epoch: 343, Loss: 0.45, Accuracy: 0.87\n",
      "Epoch: 344, Loss: 0.40, Accuracy: 0.86\n",
      "Epoch: 345, Loss: 0.37, Accuracy: 0.87\n",
      "Epoch: 346, Loss: 0.40, Accuracy: 0.87\n",
      "Epoch: 347, Loss: 0.42, Accuracy: 0.86\n",
      "Epoch: 348, Loss: 0.33, Accuracy: 0.88\n",
      "Epoch: 349, Loss: 0.39, Accuracy: 0.87\n",
      "Epoch: 350, Loss: 0.36, Accuracy: 0.88\n",
      "Epoch: 351, Loss: 0.34, Accuracy: 0.89\n",
      "Epoch: 352, Loss: 0.36, Accuracy: 0.87\n",
      "Epoch: 353, Loss: 0.40, Accuracy: 0.87\n",
      "Epoch: 354, Loss: 0.32, Accuracy: 0.88\n",
      "Epoch: 355, Loss: 0.32, Accuracy: 0.90\n",
      "Epoch: 356, Loss: 0.35, Accuracy: 0.89\n",
      "Epoch: 357, Loss: 0.31, Accuracy: 0.89\n",
      "Epoch: 358, Loss: 0.35, Accuracy: 0.88\n",
      "Epoch: 359, Loss: 0.35, Accuracy: 0.88\n",
      "Epoch: 360, Loss: 0.32, Accuracy: 0.88\n",
      "Epoch: 361, Loss: 0.33, Accuracy: 0.90\n",
      "Epoch: 362, Loss: 0.40, Accuracy: 0.86\n",
      "Epoch: 363, Loss: 0.45, Accuracy: 0.85\n",
      "Epoch: 364, Loss: 0.35, Accuracy: 0.88\n",
      "Epoch: 365, Loss: 0.32, Accuracy: 0.90\n",
      "Epoch: 366, Loss: 0.34, Accuracy: 0.90\n",
      "Epoch: 367, Loss: 0.36, Accuracy: 0.88\n",
      "Epoch: 368, Loss: 0.27, Accuracy: 0.91\n",
      "Epoch: 369, Loss: 0.33, Accuracy: 0.88\n",
      "Epoch: 370, Loss: 0.31, Accuracy: 0.89\n",
      "Epoch: 371, Loss: 0.30, Accuracy: 0.90\n",
      "Epoch: 372, Loss: 0.35, Accuracy: 0.89\n",
      "Epoch: 373, Loss: 0.36, Accuracy: 0.89\n",
      "Epoch: 374, Loss: 0.34, Accuracy: 0.89\n",
      "Epoch: 375, Loss: 0.33, Accuracy: 0.89\n",
      "Epoch: 376, Loss: 0.27, Accuracy: 0.91\n",
      "Epoch: 377, Loss: 0.28, Accuracy: 0.91\n",
      "Epoch: 378, Loss: 0.40, Accuracy: 0.88\n",
      "Epoch: 379, Loss: 0.35, Accuracy: 0.88\n",
      "Epoch: 380, Loss: 0.37, Accuracy: 0.89\n",
      "Epoch: 381, Loss: 0.32, Accuracy: 0.90\n",
      "Epoch: 382, Loss: 0.31, Accuracy: 0.89\n",
      "Epoch: 383, Loss: 0.33, Accuracy: 0.87\n",
      "Epoch: 384, Loss: 0.30, Accuracy: 0.91\n",
      "Epoch: 385, Loss: 0.29, Accuracy: 0.90\n",
      "Epoch: 386, Loss: 0.32, Accuracy: 0.90\n",
      "Epoch: 387, Loss: 0.31, Accuracy: 0.89\n",
      "Epoch: 388, Loss: 0.34, Accuracy: 0.88\n",
      "Epoch: 389, Loss: 0.31, Accuracy: 0.91\n",
      "Epoch: 390, Loss: 0.28, Accuracy: 0.91\n",
      "Epoch: 391, Loss: 0.31, Accuracy: 0.90\n",
      "Epoch: 392, Loss: 0.29, Accuracy: 0.89\n",
      "Epoch: 393, Loss: 0.26, Accuracy: 0.91\n",
      "Epoch: 394, Loss: 0.33, Accuracy: 0.90\n",
      "Epoch: 395, Loss: 0.29, Accuracy: 0.89\n",
      "Epoch: 396, Loss: 0.32, Accuracy: 0.89\n",
      "Epoch: 397, Loss: 0.35, Accuracy: 0.89\n",
      "Epoch: 398, Loss: 0.26, Accuracy: 0.91\n",
      "Epoch: 399, Loss: 0.30, Accuracy: 0.90\n",
      "Epoch: 400, Loss: 0.34, Accuracy: 0.90\n",
      "Epoch: 401, Loss: 0.28, Accuracy: 0.90\n",
      "Epoch: 402, Loss: 0.32, Accuracy: 0.89\n",
      "Epoch: 403, Loss: 0.30, Accuracy: 0.89\n",
      "Epoch: 404, Loss: 0.26, Accuracy: 0.91\n",
      "Epoch: 405, Loss: 0.28, Accuracy: 0.90\n",
      "Epoch: 406, Loss: 0.26, Accuracy: 0.91\n",
      "Epoch: 407, Loss: 0.30, Accuracy: 0.90\n",
      "Epoch: 408, Loss: 0.30, Accuracy: 0.89\n",
      "Epoch: 409, Loss: 0.32, Accuracy: 0.89\n",
      "Epoch: 410, Loss: 0.28, Accuracy: 0.91\n",
      "Epoch: 411, Loss: 0.28, Accuracy: 0.91\n",
      "Epoch: 412, Loss: 0.33, Accuracy: 0.89\n",
      "Epoch: 413, Loss: 0.25, Accuracy: 0.91\n",
      "Epoch: 414, Loss: 0.29, Accuracy: 0.89\n",
      "Epoch: 415, Loss: 0.28, Accuracy: 0.91\n",
      "Epoch: 416, Loss: 0.24, Accuracy: 0.91\n",
      "Epoch: 417, Loss: 0.25, Accuracy: 0.92\n",
      "Epoch: 418, Loss: 0.32, Accuracy: 0.90\n",
      "Epoch: 419, Loss: 0.31, Accuracy: 0.90\n",
      "Epoch: 420, Loss: 0.25, Accuracy: 0.92\n",
      "Epoch: 421, Loss: 0.23, Accuracy: 0.92\n",
      "Epoch: 422, Loss: 0.26, Accuracy: 0.91\n",
      "Epoch: 423, Loss: 0.29, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 424, Loss: 0.28, Accuracy: 0.91\n",
      "Epoch: 425, Loss: 0.27, Accuracy: 0.90\n",
      "Epoch: 426, Loss: 0.31, Accuracy: 0.90\n",
      "Epoch: 427, Loss: 0.26, Accuracy: 0.92\n",
      "Epoch: 428, Loss: 0.25, Accuracy: 0.92\n",
      "Epoch: 429, Loss: 0.22, Accuracy: 0.93\n",
      "Epoch: 430, Loss: 0.31, Accuracy: 0.89\n",
      "Epoch: 431, Loss: 0.26, Accuracy: 0.92\n",
      "Epoch: 432, Loss: 0.28, Accuracy: 0.91\n",
      "Epoch: 433, Loss: 0.22, Accuracy: 0.93\n",
      "Epoch: 434, Loss: 0.23, Accuracy: 0.92\n",
      "Epoch: 435, Loss: 0.26, Accuracy: 0.92\n",
      "Epoch: 436, Loss: 0.22, Accuracy: 0.92\n",
      "Epoch: 437, Loss: 0.26, Accuracy: 0.91\n",
      "Epoch: 438, Loss: 0.28, Accuracy: 0.91\n",
      "Epoch: 439, Loss: 0.24, Accuracy: 0.91\n",
      "Epoch: 440, Loss: 0.26, Accuracy: 0.91\n",
      "Epoch: 441, Loss: 0.26, Accuracy: 0.92\n",
      "Epoch: 442, Loss: 0.22, Accuracy: 0.92\n",
      "Epoch: 443, Loss: 0.30, Accuracy: 0.90\n",
      "Epoch: 444, Loss: 0.24, Accuracy: 0.92\n",
      "Epoch: 445, Loss: 0.20, Accuracy: 0.93\n",
      "Epoch: 446, Loss: 0.24, Accuracy: 0.92\n",
      "Epoch: 447, Loss: 0.23, Accuracy: 0.93\n",
      "Epoch: 448, Loss: 0.23, Accuracy: 0.93\n",
      "Epoch: 449, Loss: 0.20, Accuracy: 0.93\n",
      "Epoch: 450, Loss: 0.19, Accuracy: 0.93\n",
      "Epoch: 451, Loss: 0.21, Accuracy: 0.93\n",
      "Epoch: 452, Loss: 0.25, Accuracy: 0.91\n",
      "Epoch: 453, Loss: 0.26, Accuracy: 0.91\n",
      "Epoch: 454, Loss: 0.25, Accuracy: 0.91\n",
      "Epoch: 455, Loss: 0.25, Accuracy: 0.92\n",
      "Epoch: 456, Loss: 0.20, Accuracy: 0.94\n",
      "Epoch: 457, Loss: 0.20, Accuracy: 0.93\n",
      "Epoch: 458, Loss: 0.22, Accuracy: 0.94\n",
      "Epoch: 459, Loss: 0.22, Accuracy: 0.93\n",
      "Epoch: 460, Loss: 0.23, Accuracy: 0.92\n",
      "Epoch: 461, Loss: 0.23, Accuracy: 0.93\n",
      "Epoch: 462, Loss: 0.20, Accuracy: 0.93\n",
      "Epoch: 463, Loss: 0.19, Accuracy: 0.92\n",
      "Epoch: 464, Loss: 0.23, Accuracy: 0.93\n",
      "Epoch: 465, Loss: 0.20, Accuracy: 0.93\n",
      "Epoch: 466, Loss: 0.20, Accuracy: 0.93\n",
      "Epoch: 467, Loss: 0.19, Accuracy: 0.94\n",
      "Epoch: 468, Loss: 0.22, Accuracy: 0.92\n",
      "Epoch: 469, Loss: 0.24, Accuracy: 0.91\n",
      "Epoch: 470, Loss: 0.24, Accuracy: 0.92\n",
      "Epoch: 471, Loss: 0.19, Accuracy: 0.92\n",
      "Epoch: 472, Loss: 0.22, Accuracy: 0.93\n",
      "Epoch: 473, Loss: 0.23, Accuracy: 0.93\n",
      "Epoch: 474, Loss: 0.17, Accuracy: 0.94\n",
      "Epoch: 475, Loss: 0.21, Accuracy: 0.94\n",
      "Epoch: 476, Loss: 0.22, Accuracy: 0.93\n",
      "Epoch: 477, Loss: 0.24, Accuracy: 0.93\n",
      "Epoch: 478, Loss: 0.24, Accuracy: 0.92\n",
      "Epoch: 479, Loss: 0.22, Accuracy: 0.93\n",
      "Epoch: 480, Loss: 0.23, Accuracy: 0.92\n",
      "Epoch: 481, Loss: 0.21, Accuracy: 0.93\n",
      "Epoch: 482, Loss: 0.20, Accuracy: 0.93\n",
      "Epoch: 483, Loss: 0.20, Accuracy: 0.93\n",
      "Epoch: 484, Loss: 0.23, Accuracy: 0.92\n",
      "Epoch: 485, Loss: 0.18, Accuracy: 0.94\n",
      "Epoch: 486, Loss: 0.23, Accuracy: 0.92\n",
      "Epoch: 487, Loss: 0.18, Accuracy: 0.94\n",
      "Epoch: 488, Loss: 0.19, Accuracy: 0.93\n",
      "Epoch: 489, Loss: 0.21, Accuracy: 0.93\n",
      "Epoch: 490, Loss: 0.18, Accuracy: 0.94\n",
      "Epoch: 491, Loss: 0.20, Accuracy: 0.94\n",
      "Epoch: 492, Loss: 0.24, Accuracy: 0.92\n",
      "Epoch: 493, Loss: 0.19, Accuracy: 0.94\n",
      "Epoch: 494, Loss: 0.17, Accuracy: 0.93\n",
      "Epoch: 495, Loss: 0.17, Accuracy: 0.94\n",
      "Epoch: 496, Loss: 0.21, Accuracy: 0.93\n",
      "Epoch: 497, Loss: 0.21, Accuracy: 0.93\n",
      "Epoch: 498, Loss: 0.19, Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "num_epochs=500   # Just for demo, adjust this higher.\n",
    "training(myModel, train_dl, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae39f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Inference\n",
    "# ----------------------------\n",
    "def inference (model, val_dl):\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in val_dl:\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecbf3327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58, Total items: 218\n"
     ]
    }
   ],
   "source": [
    "# Run inference on trained model with the validation set\n",
    "inference(myModel, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taux de reconnaissance par classe et confussion matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
